{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logit(r1, r2, theta1, theta2):\n",
    "    return r1*r2*np.cos(theta1 - theta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grad_u(r1, r2, theta1, theta2):\n",
    "    return -1.0*r1*r2*np.sin(theta1 - theta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def grad(theta1, theta2):\n",
    "    error = sigmoid(logit(r1, r2, theta1, theta2))-1\n",
    "    return error*grad_u(r1, r2, theta1, theta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_logits(r1,r2,theta1,theta2):\n",
    "    cos = tf.cos(theta1-theta2)\n",
    "    rad = tf.multiply(r1,r2)\n",
    "    return tf.multiply(cos, rad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "example = 1\n",
    "theta1 = tf.Variable(math.pi/3.0, name='theta1')\n",
    "theta2 = tf.Variable(math.pi/6.0, name='theta2')\n",
    "theta3 = tf.Variable(math.pi/3.0, name='theta1')\n",
    "theta4 = tf.Variable(math.pi/6.0, name='theta2')\n",
    "radius1 = tf.Variable(1.0)\n",
    "radius2 = tf.Variable(1.0)\n",
    "radius3 = tf.Variable(1.0)\n",
    "radius4 = tf.Variable(1.0)\n",
    "\n",
    "b = tf.Variable(1.0, name='b')\n",
    "true_logits = tf_logits(radius1,radius2,theta1,theta2)\n",
    "sampled_logits = tf_logits(radius3,radius4,theta3,theta4)\n",
    "true_xent = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            logits=true_logits, labels=tf.ones_like(true_logits))\n",
    "sampled_xent = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            logits=sampled_logits, labels=tf.zeros_like(sampled_logits))\n",
    "loss = true_xent + sampled_xent + b\n",
    "opt = tf.train.GradientDescentOptimizer(1.0)\n",
    "grads = opt.compute_gradients(loss, [theta1, theta2, theta3, theta4])\n",
    "apply_grad = opt.apply_gradients(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('grad should be: ', 0.14804100218137506)\n",
      "[(0.14804101, 1.0471976), (-0.14804101, 0.52359879), (-0.35195899, 1.0471976), (0.35195899, 0.52359879)]\n",
      "('grad should be: ', 0.061811795327619691)\n",
      "[(0.06181179, 0.89915657), (-0.06181179, 0.6716398), (-0.54932332, 1.3991566), (0.54932332, 0.1716398)]\n",
      "('grad should be: ', 0.028001014710096084)\n",
      "[(0.028001014, 0.83734477), (-0.028001014, 0.7334516), (-0.24390303, 1.9484799), (0.24390303, -0.37768352)]\n",
      "('grad should be: ', 0.012885782755457004)\n",
      "[(0.012885782, 0.80934376), (-0.012885782, 0.76145262), (-0.089949965, 2.1923828), (0.089949965, -0.62158656)]\n",
      "('grad should be: ', 0.0059494347403406993)\n",
      "[(0.0059494344, 0.79645795), (-0.0059494344, 0.77433842), (-0.03990056, 2.2823329), (0.03990056, -0.71153653)]\n",
      "('grad should be: ', 0.0027488123380452786)\n",
      "[(0.0027488123, 0.79050851), (-0.0027488123, 0.78028786), (-0.018283853, 2.3222334), (0.018283853, -0.75143707)]\n",
      "('grad should be: ', 0.001270235281196252)\n",
      "[(0.0012702353, 0.78775972), (-0.0012702353, 0.78303665), (-0.0084341932, 2.3405173), (0.0084341932, -0.76972091)]\n",
      "('grad should be: ', 0.00058699290197666398)\n",
      "[(0.00058699289, 0.78648949), (-0.00058699289, 0.78430688), (-0.0038960446, 2.3489516), (0.0038960446, -0.77815509)]\n",
      "('grad should be: ', 0.00027126240176393856)\n",
      "[(0.0002712624, 0.7859025), (-0.0002712624, 0.78489387), (-0.0018003074, 2.3528476), (0.0018003074, -0.78205115)]\n",
      "('grad should be: ', 0.00012535583654579792)\n",
      "[(0.00012535583, 0.78563124), (-0.00012535583, 0.78516513), (-0.00083194324, 2.3546479), (0.00083194324, -0.78385144)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(10):\n",
    "        b_val = 1.0    \n",
    "        t1, t2 = sess.run([theta1, theta2])\n",
    "        theta1_grad = grad(t1, t2)\n",
    "        print('grad should be: ', theta1_grad)\n",
    "        grad_vals = sess.run(grads, feed_dict={b: b_val})\n",
    "        print(grad_vals)\n",
    "        sess.run(apply_grad, feed_dict={b: b_val})\n",
    "#         assert(grad_vals[0][0] == theta1_grad)\n",
    "\n",
    "# r = tf.Variable([2.0,1.0, 3.0], name='r')\n",
    "# # b placeholder (simualtes the \"data\" part of the training)\n",
    "# b = tf.placeholder(tf.float32)\n",
    "# # make model (1/2)(x-b)^2\n",
    "# example_radius = tf.nn.embedding_lookup(r, example)\n",
    "# example_theta = tf.nn.embedding_lookup(theta, example)\n",
    "# loss = example_radius*tf.cos(example_theta) - b\n",
    "# learning_rate = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.Variable([0,1,2,3], dtype=tf.float32)\n",
    "y = tf.Variable([0,1,2,3], dtype=tf.float32)\n",
    "ex1 = tf.placeholder(tf.int32)\n",
    "ex2 = tf.placeholder(tf.int32)\n",
    "# example = tf.Variable(1)\n",
    "a = tf.nn.embedding_lookup(x,ex1)\n",
    "b = tf.nn.embedding_lookup(y,ex2)\n",
    "c = tf.cos(tf.subtract(a, b))\n",
    "loss = c - 1.0\n",
    "opt = tf.train.GradientDescentOptimizer(1.0)\n",
    "grad_y = opt.compute_gradients(loss, [y])\n",
    "grad_x = opt.compute_gradients(loss, [x])\n",
    "apply_grad = opt.apply_gradients(grad_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def grad_y_fun(y, yidx, x, xidx):\n",
    "    print('evaluating grad at y: ', y, 'and index: ', yidx)\n",
    "    yvals = y[yidx]\n",
    "    xvals = x[xidx]\n",
    "#     print('vals are: ', vals)\n",
    "    return np.sin(xvals - yvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  2.  3.]\n",
      "[(IndexedSlicesValue(values=array([-0.84147096], dtype=float32), indices=array([2], dtype=int32), dense_shape=array([4], dtype=int32)), array([ 0.,  1.,  2.,  3.], dtype=float32))]\n",
      "('evaluating grad at y: ', array([ 0.,  1.,  2.,  3.], dtype=float32), 'and index: ', array([2]))\n",
      "('grad should be: ', array([-0.84147096], dtype=float32))\n",
      "[ 0.          1.          2.84147096  3.        ]\n",
      "[ 0.54030228]\n",
      "[ 0.          1.          2.84147096  3.        ]\n",
      "[(IndexedSlicesValue(values=array([-0.96359074], dtype=float32), indices=array([2], dtype=int32), dense_shape=array([4], dtype=int32)), array([ 0.        ,  1.        ,  2.84147096,  3.        ], dtype=float32))]\n",
      "('evaluating grad at y: ', array([ 0.        ,  1.        ,  2.84147096,  3.        ], dtype=float32), 'and index: ', array([2]))\n",
      "('grad should be: ', array([-0.96359074], dtype=float32))\n",
      "[ 0.          1.          3.80506182  3.        ]\n",
      "[-0.26738158]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(20):\n",
    "        e1 = np.array([1])\n",
    "        e2 = np.array([2])\n",
    "        grad, y_val, x_val = sess.run([grad_y, y, x], feed_dict={ex1:e1, ex2:e2})\n",
    "#         print(cn)\n",
    "        print(y_val)\n",
    "        print(grad)\n",
    "        assert(grad.values == grad_y_fun(y_val, e2, x_val, e1))\n",
    "        print('grad should be: ', grad_y_fun(y_val, e2, x_val, e1))\n",
    "        _, cn, yval = sess.run([apply_grad, c, y], feed_dict={ex1:e1, ex2:e2})\n",
    "        print(yval)\n",
    "        print(cn)  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90929742682568171"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sin(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.99999995408515685"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arcsin(-0.84147096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
